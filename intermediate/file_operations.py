# Pythonå­¦ä¹ é¡¹ç›® - ä¸­çº§å†…å®¹ï¼šæ–‡ä»¶æ“ä½œ
# å­¦ä¹ åºå·ï¼šç¬¬6é˜¶æ®µ ç¬¬1è¯¾ - æ–‡ä»¶æ“ä½œ
# å»ºè®®å­¦ä¹ æ—¶é—´ï¼š90-120åˆ†é’Ÿ
# å‰ç½®çŸ¥è¯†ï¼šç¬¬1-5é˜¶æ®µ - åŸºç¡€è¯­æ³•åˆ°å¼‚å¸¸å¤„ç†
# ä¸‹ä¸€è¯¾ï¼šç¬¬6é˜¶æ®µ ç¬¬2è¯¾ - æ ‡å‡†åº“ç²¾é€‰ (standard_library.py)
# æœ¬æ¨¡å—ä»‹ç»Pythonæ–‡ä»¶æ“ä½œçš„æ ¸å¿ƒæ¦‚å¿µå’Œå®é™…åº”ç”¨

"""
æ–‡ä»¶æ“ä½œæ˜¯Pythonç¼–ç¨‹ä¸­çš„é‡è¦å†…å®¹ï¼Œæ¶‰åŠï¼š
1. æ–‡ä»¶çš„æ‰“å¼€ã€è¯»å–ã€å†™å…¥å’Œå…³é—­
2. æ–‡æœ¬æ–‡ä»¶å’ŒäºŒè¿›åˆ¶æ–‡ä»¶
3. ç›®å½•æ“ä½œå’Œæ–‡ä»¶ç®¡ç†
4. è·¯å¾„å¤„ç†
5. CSVå’ŒJSONæ–‡ä»¶å¤„ç†
6. æ–‡ä»¶æƒé™å’Œå±æ€§
7. ä¸´æ—¶æ–‡ä»¶
8. é«˜çº§æ–‡ä»¶æ“ä½œæŠ€å·§
"""

import os
import shutil
import tempfile
import csv
import json
import pathlib
from datetime import datetime
from typing import List, Dict, Any, Optional, Union

# ===== 1. æ–‡ä»¶åŸºç¡€æ“ä½œ =====

print("=== æ–‡ä»¶åŸºç¡€æ“ä½œ ===")

# æ–‡ä»¶æ‰“å¼€æ¨¡å¼
print("æ–‡ä»¶æ‰“å¼€æ¨¡å¼:")
print("  'r'  - è¯»å–ï¼ˆé»˜è®¤ï¼‰")
print("  'w'  - å†™å…¥ï¼ˆè¦†ç›–ï¼‰")
print("  'a'  - è¿½åŠ ")
print("  'x'  - ç‹¬å åˆ›å»º")
print("  'b'  - äºŒè¿›åˆ¶æ¨¡å¼")
print("  't'  - æ–‡æœ¬æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰")
print("  '+'  - è¯»å†™æ¨¡å¼")

# ===== 2. æ–‡æœ¬æ–‡ä»¶æ“ä½œ =====

print("\n=== æ–‡æœ¬æ–‡ä»¶æ“ä½œ ===")

# åˆ›å»ºç¤ºä¾‹æ–‡æœ¬æ–‡ä»¶
sample_text = """Pythonæ–‡ä»¶æ“ä½œç¤ºä¾‹

è¿™æ˜¯ç¬¬ä¸€æ®µæ–‡æœ¬ã€‚
åŒ…å«å¤šè¡Œå†…å®¹ã€‚

ç¬¬äºŒæ®µï¼š
- é¡¹ç›®1
- é¡¹ç›®2
- é¡¹ç›®3

ç»“æŸè¯­ï¼šæ–‡ä»¶æ“ä½œå¾ˆé‡è¦ï¼
"""

# å†™å…¥æ–‡ä»¶
print("å†™å…¥æ–‡æœ¬æ–‡ä»¶:")
with open('python_learning/utils/sample.txt', 'w', encoding='utf-8') as file:
    file.write(sample_text)
    print("  æ–‡ä»¶å·²åˆ›å»ºå¹¶å†™å…¥å†…å®¹")

# è¯»å–æ–‡ä»¶ - å¤šç§æ–¹å¼
print("\nè¯»å–æ–‡æœ¬æ–‡ä»¶:")

# æ–¹å¼1: read() - è¯»å–å…¨éƒ¨å†…å®¹
with open('python_learning/utils/sample.txt', 'r', encoding='utf-8') as file:
    content = file.read()
    print(f"  read() - æ€»å­—ç¬¦æ•°: {len(content)}")

# æ–¹å¼2: readline() - è¯»å–ä¸€è¡Œ
with open('python_learning/utils/sample.txt', 'r', encoding='utf-8') as file:
    first_line = file.readline().strip()
    second_line = file.readline().strip()
    print(f"  readline() - ç¬¬ä¸€è¡Œ: '{first_line}'")
    print(f"  readline() - ç¬¬äºŒè¡Œ: '{second_line}'")

# æ–¹å¼3: readlines() - è¯»å–æ‰€æœ‰è¡Œ
with open('python_learning/utils/sample.txt', 'r', encoding='utf-8') as file:
    lines = file.readlines()
    print(f"  readlines() - æ€»è¡Œæ•°: {len(lines)}")
    print(f"  readlines() - ç¬¬ä¸€è¡Œå†…å®¹: '{lines[0].strip()}'")

# æ–¹å¼4: é€è¡Œè¿­ä»£
print("  é€è¡Œè¿­ä»£:")
with open('python_learning/utils/sample.txt', 'r', encoding='utf-8') as file:
    for i, line in enumerate(file, 1):
        print(f"    ç¬¬{i}è¡Œ: {line.strip()}")

# ===== 3. æ–‡ä»¶æŒ‡é’ˆå’Œå®šä½ =====

print("\n=== æ–‡ä»¶æŒ‡é’ˆå’Œå®šä½ ===")

with open('python_learning/utils/sample.txt', 'r', encoding='utf-8') as file:
    # æŸ¥çœ‹å½“å‰ä½ç½®
    print(f"åˆå§‹ä½ç½®: {file.tell()}")

    # è¯»å–ä¸€äº›å†…å®¹
    content = file.read(10)
    print(f"è¯»å–10ä¸ªå­—ç¬¦: '{content}'")
    print(f"å½“å‰ä½ç½®: {file.tell()}")

    # ç§»åŠ¨åˆ°æŒ‡å®šä½ç½®
    file.seek(0)  # ç§»åŠ¨åˆ°æ–‡ä»¶å¼€å¤´
    print(f"seek(0)åä½ç½®: {file.tell()}")

    file.seek(5)  # ç§»åŠ¨åˆ°ç¬¬5ä¸ªå­—èŠ‚
    print(f"seek(5)åä½ç½®: {file.tell()}")

    content = file.read(10)
    print(f"ä»ä½ç½®5è¯»å–10ä¸ªå­—ç¬¦: '{content}'")

# ===== 4. è¿½åŠ å’Œä¿®æ”¹æ–‡ä»¶ =====

print("\n=== è¿½åŠ å’Œä¿®æ”¹æ–‡ä»¶ ===")

# è¿½åŠ å†…å®¹
with open('python_learning/utils/sample.txt', 'a', encoding='utf-8') as file:
    file.write("\n\nè¿½åŠ çš„å†…å®¹ï¼š\n")
    file.write("è¿™æ˜¯æ–°æ·»åŠ çš„è¡Œã€‚\n")
    file.write(f"æ·»åŠ æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

print("å†…å®¹å·²è¿½åŠ åˆ°æ–‡ä»¶")

# ===== 5. äºŒè¿›åˆ¶æ–‡ä»¶æ“ä½œ =====

print("\n=== äºŒè¿›åˆ¶æ–‡ä»¶æ“ä½œ ===")

# å†™å…¥äºŒè¿›åˆ¶æ•°æ®
binary_data = bytes(range(256))  # 0-255çš„å­—èŠ‚

with open('python_learning/utils/binary_sample.bin', 'wb') as file:
    file.write(binary_data)
    print("äºŒè¿›åˆ¶æ–‡ä»¶å·²åˆ›å»º")

# è¯»å–äºŒè¿›åˆ¶æ•°æ®
with open('python_learning/utils/binary_sample.bin', 'rb') as file:
    # è¯»å–å‰16ä¸ªå­—èŠ‚
    first_16 = file.read(16)
    print(f"å‰16ä¸ªå­—èŠ‚: {list(first_16)}")

    # è¯»å–å‰©ä½™å†…å®¹
    rest = file.read()
    print(f"å‰©ä½™å­—èŠ‚æ•°: {len(rest)}")

# ===== 6. ç›®å½•æ“ä½œ =====

print("\n=== ç›®å½•æ“ä½œ ===")

# åˆ›å»ºç›®å½•
test_dir = 'python_learning/utils/test_directory'
sub_dir = os.path.join(test_dir, 'subdir')

try:
    os.makedirs(sub_dir, exist_ok=True)
    print(f"ç›®å½•å·²åˆ›å»º: {sub_dir}")
except OSError as e:
    print(f"åˆ›å»ºç›®å½•å¤±è´¥: {e}")

# åˆ—å‡ºç›®å½•å†…å®¹
print(f"\n{test_dir} ç›®å½•å†…å®¹:")
try:
    contents = os.listdir(test_dir)
    for item in contents:
        full_path = os.path.join(test_dir, item)
        if os.path.isdir(full_path):
            print(f"  ğŸ“ {item}/")
        else:
            print(f"  ğŸ“„ {item}")
except OSError as e:
    print(f"è¯»å–ç›®å½•å¤±è´¥: {e}")

# ===== 7. æ–‡ä»¶å’Œç›®å½•ç®¡ç† =====

print("\n=== æ–‡ä»¶å’Œç›®å½•ç®¡ç† ===")

# æ–‡ä»¶é‡å‘½å
old_name = 'python_learning/utils/sample.txt'
new_name = 'python_learning/utils/renamed_sample.txt'

try:
    os.rename(old_name, new_name)
    print(f"æ–‡ä»¶å·²é‡å‘½å: {old_name} -> {new_name}")
except OSError as e:
    print(f"é‡å‘½åå¤±è´¥: {e}")

# æ–‡ä»¶åˆ é™¤
try:
    os.remove('python_learning/utils/binary_sample.bin')
    print("äºŒè¿›åˆ¶æ–‡ä»¶å·²åˆ é™¤")
except OSError as e:
    print(f"åˆ é™¤å¤±è´¥: {e}")

# é€’å½’åˆ é™¤ç›®å½•
try:
    shutil.rmtree(test_dir)
    print(f"ç›®å½•å·²é€’å½’åˆ é™¤: {test_dir}")
except OSError as e:
    print(f"åˆ é™¤ç›®å½•å¤±è´¥: {e}")

# ===== 8. è·¯å¾„å¤„ç† =====

print("\n=== è·¯å¾„å¤„ç† ===")

# å½“å‰å·¥ä½œç›®å½•
current_dir = os.getcwd()
print(f"å½“å‰å·¥ä½œç›®å½•: {current_dir}")

# è·¯å¾„æ‹¼æ¥
path1 = os.path.join('python_learning', 'utils', 'test.txt')
print(f"è·¯å¾„æ‹¼æ¥: {path1}")

# è·¯å¾„åˆ†å‰²
dirname, basename = os.path.split(path1)
print(f"è·¯å¾„åˆ†å‰² - ç›®å½•: {dirname}, æ–‡ä»¶å: {basename}")

# æ–‡ä»¶æ‰©å±•å
name, ext = os.path.splitext(basename)
print(f"æ–‡ä»¶å: {name}, æ‰©å±•å: {ext}")

# åˆ¤æ–­è·¯å¾„ç±»å‹
test_paths = [
    'python_learning/utils',
    new_name,
    'nonexistent_file.txt'
]

for path in test_paths:
    print(f"è·¯å¾„: {path}")
    print(f"  å­˜åœ¨: {os.path.exists(path)}")
    print(f"  æ˜¯æ–‡ä»¶: {os.path.isfile(path)}")
    print(f"  æ˜¯ç›®å½•: {os.path.isdir(path)}")
    if os.path.exists(path):
        print(f"  å¤§å°: {os.path.getsize(path)} bytes")
        print(f"  ä¿®æ”¹æ—¶é—´: {datetime.fromtimestamp(os.path.getmtime(path))}")

# ===== 9. pathlibæ¨¡å— =====

print("\n=== pathlibæ¨¡å—ï¼ˆç°ä»£è·¯å¾„å¤„ç†ï¼‰ ===")

from pathlib import Path

# åˆ›å»ºPathå¯¹è±¡
project_root = Path('python_learning')
utils_dir = project_root / 'utils'

print(f"é¡¹ç›®æ ¹ç›®å½•: {project_root}")
print(f"å·¥å…·ç›®å½•: {utils_dir}")

# è·¯å¾„æ“ä½œ
print(f"å·¥å…·ç›®å½•å­˜åœ¨: {utils_dir.exists()}")
print(f"å·¥å…·ç›®å½•æ˜¯ç›®å½•: {utils_dir.is_dir()}")

# åˆ—å‡ºç›®å½•å†…å®¹
if utils_dir.exists():
    print("å·¥å…·ç›®å½•å†…å®¹:")
    for item in utils_dir.iterdir():
        if item.is_file():
            print(f"  ğŸ“„ {item.name} ({item.stat().st_size} bytes)")
        elif item.is_dir():
            print(f"  ğŸ“ {item.name}/")

# æ–‡ä»¶åŒ¹é…
txt_files = list(utils_dir.glob('*.txt'))
print(f"æ‰¾åˆ°çš„æ–‡æœ¬æ–‡ä»¶: {[f.name for f in txt_files]}")

# ===== 10. CSVæ–‡ä»¶å¤„ç† =====

print("\n=== CSVæ–‡ä»¶å¤„ç† ===")

# å‡†å¤‡CSVæ•°æ®
csv_data = [
    ['å§“å', 'å¹´é¾„', 'åŸå¸‚', 'èŒä¸š'],
    ['å¼ ä¸‰', 25, 'åŒ—äº¬', 'å·¥ç¨‹å¸ˆ'],
    ['æå››', 30, 'ä¸Šæµ·', 'è®¾è®¡å¸ˆ'],
    ['ç‹äº”', 28, 'å¹¿å·', 'æ•™å¸ˆ'],
    ['èµµå…­', 35, 'æ·±åœ³', 'ç»ç†']
]

# å†™å…¥CSVæ–‡ä»¶
csv_filename = 'python_learning/utils/sample_data.csv'
with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:
    writer = csv.writer(csvfile)
    writer.writerows(csv_data)
    print("CSVæ–‡ä»¶å·²åˆ›å»º")

# è¯»å–CSVæ–‡ä»¶
print("è¯»å–CSVæ–‡ä»¶:")
with open(csv_filename, 'r', newline='', encoding='utf-8') as csvfile:
    reader = csv.reader(csvfile)
    for i, row in enumerate(reader):
        if i == 0:
            print(f"è¡¨å¤´: {row}")
        else:
            print(f"è®°å½•{i}: {row}")

# ä½¿ç”¨DictReaderè¿›è¡Œå­—å…¸å¼è¯»å–
print("\nå­—å…¸å¼è¯»å–CSV:")
with open(csv_filename, 'r', newline='', encoding='utf-8') as csvfile:
    reader = csv.DictReader(csvfile)
    for row in reader:
        print(f"  {row['å§“å']}: {row['å¹´é¾„']}å², {row['åŸå¸‚']}, {row['èŒä¸š']}")

# ===== 11. JSONæ–‡ä»¶å¤„ç† =====

print("\n=== JSONæ–‡ä»¶å¤„ç† ===")

# å‡†å¤‡JSONæ•°æ®
json_data = {
    "company": "Pythonå­¦ä¹ å…¬å¸",
    "employees": [
        {
            "name": "å¼ ä¸‰",
            "age": 25,
            "department": "å·¥ç¨‹éƒ¨",
            "skills": ["Python", "JavaScript", "SQL"],
            "salary": 8000
        },
        {
            "name": "æå››",
            "age": 30,
            "department": "è®¾è®¡éƒ¨",
            "skills": ["Photoshop", "Illustrator", "Sketch"],
            "salary": 7000
        }
    ],
    "projects": {
        "current": ["ç½‘ç«™é‡æ„", "ç§»åŠ¨åº”ç”¨å¼€å‘"],
        "completed": ["ç”µå•†å¹³å°", "æ•°æ®å¯è§†åŒ–å·¥å…·"]
    },
    "metadata": {
        "created": datetime.now().isoformat(),
        "version": "1.0"
    }
}

# å†™å…¥JSONæ–‡ä»¶
json_filename = 'python_learning/utils/sample_data.json'
with open(json_filename, 'w', encoding='utf-8') as jsonfile:
    json.dump(json_data, jsonfile, ensure_ascii=False, indent=2)
    print("JSONæ–‡ä»¶å·²åˆ›å»º")

# è¯»å–JSONæ–‡ä»¶
print("è¯»å–JSONæ–‡ä»¶:")
with open(json_filename, 'r', encoding='utf-8') as jsonfile:
    loaded_data = json.load(jsonfile)

print(f"å…¬å¸åç§°: {loaded_data['company']}")
print(f"å‘˜å·¥æ•°é‡: {len(loaded_data['employees'])}")
print(f"å½“å‰é¡¹ç›®: {loaded_data['projects']['current']}")

# ===== 12. ä¸´æ—¶æ–‡ä»¶ =====

print("\n=== ä¸´æ—¶æ–‡ä»¶ ===")

# ä½¿ç”¨tempfileæ¨¡å—åˆ›å»ºä¸´æ—¶æ–‡ä»¶
with tempfile.NamedTemporaryFile(mode='w+', suffix='.txt', delete=False) as temp_file:
    temp_file.write("è¿™æ˜¯ä¸´æ—¶æ–‡ä»¶å†…å®¹\n")
    temp_file.write("å®ƒä¼šåœ¨ç¨‹åºç»“æŸåè¢«æ¸…ç†\n")
    temp_filename = temp_file.name
    print(f"ä¸´æ—¶æ–‡ä»¶å·²åˆ›å»º: {temp_filename}")

# è¯»å–ä¸´æ—¶æ–‡ä»¶å†…å®¹
with open(temp_filename, 'r') as temp_file:
    content = temp_file.read()
    print(f"ä¸´æ—¶æ–‡ä»¶å†…å®¹:\n{content}")

# æ‰‹åŠ¨åˆ é™¤ä¸´æ—¶æ–‡ä»¶
os.unlink(temp_filename)
print("ä¸´æ—¶æ–‡ä»¶å·²æ‰‹åŠ¨åˆ é™¤")

# ä¸´æ—¶ç›®å½•
with tempfile.TemporaryDirectory() as temp_dir:
    print(f"ä¸´æ—¶ç›®å½•å·²åˆ›å»º: {temp_dir}")

    # åœ¨ä¸´æ—¶ç›®å½•ä¸­åˆ›å»ºæ–‡ä»¶
    temp_file_path = os.path.join(temp_dir, 'temp_data.txt')
    with open(temp_file_path, 'w') as f:
        f.write("ä¸´æ—¶ç›®å½•ä¸­çš„æ–‡ä»¶")

    print(f"ä¸´æ—¶ç›®å½•å†…å®¹: {os.listdir(temp_dir)}")

print("ä¸´æ—¶ç›®å½•å·²è‡ªåŠ¨æ¸…ç†")

# ===== 13. æ–‡ä»¶æƒé™å’Œå±æ€§ =====

print("\n=== æ–‡ä»¶æƒé™å’Œå±æ€§ ===")

# æ£€æŸ¥æ–‡ä»¶æƒé™
test_file = new_name  # ä½¿ç”¨ä¹‹å‰é‡å‘½åçš„æ–‡ä»¶
if os.path.exists(test_file):
    # æ–‡ä»¶çŠ¶æ€ä¿¡æ¯
    stat_info = os.stat(test_file)
    print(f"æ–‡ä»¶: {test_file}")
    print(f"  å¤§å°: {stat_info.st_size} bytes")
    print(f"  ä¿®æ”¹æ—¶é—´: {datetime.fromtimestamp(stat_info.st_mtime)}")
    print(f"  è®¿é—®æ—¶é—´: {datetime.fromtimestamp(stat_info.st_atime)}")
    print(f"  åˆ›å»ºæ—¶é—´: {datetime.fromtimestamp(stat_info.st_ctime)}")

    # æƒé™æ£€æŸ¥
    print(f"  å¯è¯»: {os.access(test_file, os.R_OK)}")
    print(f"  å¯å†™: {os.access(test_file, os.W_OK)}")
    print(f"  å¯æ‰§è¡Œ: {os.access(test_file, os.X_OK)}")

# ===== 14. é«˜çº§æ–‡ä»¶æ“ä½œæŠ€å·§ =====

print("\n=== é«˜çº§æ–‡ä»¶æ“ä½œæŠ€å·§ ===")

# æ–‡ä»¶å¤‡ä»½
def backup_file(filename):
    """åˆ›å»ºæ–‡ä»¶å¤‡ä»½"""
    if not os.path.exists(filename):
        return False

    backup_name = filename + '.backup'
    shutil.copy2(filename, backup_name)
    print(f"å¤‡ä»½å·²åˆ›å»º: {backup_name}")
    return True

# æ–‡ä»¶åˆå¹¶
def merge_files(output_file, *input_files):
    """åˆå¹¶å¤šä¸ªæ–‡ä»¶"""
    with open(output_file, 'w', encoding='utf-8') as outfile:
        for input_file in input_files:
            if os.path.exists(input_file):
                with open(input_file, 'r', encoding='utf-8') as infile:
                    outfile.write(f"=== {os.path.basename(input_file)} ===\n")
                    outfile.write(infile.read())
                    outfile.write("\n\n")
                print(f"å·²åˆå¹¶: {input_file}")

# æ–‡ä»¶æŸ¥æ‰¾
def find_files(directory, extension=None, name_pattern=None):
    """æŸ¥æ‰¾æ–‡ä»¶"""
    matches = []
    for root, dirs, files in os.walk(directory):
        for file in files:
            if extension and not file.endswith(extension):
                continue
            if name_pattern and name_pattern not in file:
                continue
            matches.append(os.path.join(root, file))
    return matches

# ===== 15. æ–‡ä»¶æ“ä½œå®‰å…¨æ€§å’Œæœ€ä½³å®è·µ =====

print("\n=== æ–‡ä»¶æ“ä½œå®‰å…¨æ€§å’Œæœ€ä½³å®è·µ ===")

# å®‰å…¨çš„æ–‡ä»¶æ‰“å¼€æ–¹å¼
def safe_file_operation(filename, operation):
    """å®‰å…¨çš„æ–‡ä»¶æ“ä½œ"""
    try:
        with open(filename, 'r', encoding='utf-8') as file:
            return operation(file)
    except FileNotFoundError:
        print(f"æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
        return None
    except PermissionError:
        print(f"æƒé™ä¸è¶³: {filename}")
        return None
    except UnicodeDecodeError:
        print(f"ç¼–ç é”™è¯¯ï¼Œå°è¯•å…¶ä»–ç¼–ç : {filename}")
        try:
            with open(filename, 'r', encoding='gbk') as file:
                return operation(file)
        except UnicodeDecodeError:
            print(f"æ— æ³•è§£ç æ–‡ä»¶: {filename}")
            return None
    except Exception as e:
        print(f"æ–‡ä»¶æ“ä½œé”™è¯¯: {e}")
        return None

# ä½¿ç”¨å®‰å…¨æ–‡ä»¶æ“ä½œ
def count_words(file_obj):
    """ç»Ÿè®¡å•è¯æ•°"""
    content = file_obj.read()
    return len(content.split())

word_count = safe_file_operation(new_name, count_words)
if word_count is not None:
    print(f"æ–‡ä»¶å•è¯æ•°: {word_count}")

# ===== ç»ƒä¹  =====

print("\n=== ç»ƒä¹ æ—¶é—´ ===")

# ç»ƒä¹ 1: æ–‡ä»¶å†…å®¹åˆ†æå™¨
def file_analyzer(filename):
    """æ–‡ä»¶å†…å®¹åˆ†æå™¨"""
    if not os.path.exists(filename):
        return f"æ–‡ä»¶ä¸å­˜åœ¨: {filename}"

    stats = {
        'lines': 0,
        'words': 0,
        'characters': 0,
        'size': os.path.getsize(filename)
    }

    with open(filename, 'r', encoding='utf-8') as file:
        for line in file:
            stats['lines'] += 1
            stats['characters'] += len(line)
            stats['words'] += len(line.split())

    return stats

# æµ‹è¯•æ–‡ä»¶åˆ†æå™¨
analyzer_result = file_analyzer(new_name)
if isinstance(analyzer_result, dict):
    print("æ–‡ä»¶åˆ†æç»“æœ:")
    print(f"  è¡Œæ•°: {analyzer_result['lines']}")
    print(f"  å•è¯æ•°: {analyzer_result['words']}")
    print(f"  å­—ç¬¦æ•°: {analyzer_result['characters']}")
    print(f"  æ–‡ä»¶å¤§å°: {analyzer_result['size']} bytes")
else:
    print(analyzer_result)

# ç»ƒä¹ 2: æ‰¹é‡æ–‡ä»¶é‡å‘½å
def batch_rename(directory, old_pattern, new_pattern):
    """æ‰¹é‡é‡å‘½åæ–‡ä»¶"""
    if not os.path.exists(directory):
        return f"ç›®å½•ä¸å­˜åœ¨: {directory}"

    renamed_count = 0
    for filename in os.listdir(directory):
        if old_pattern in filename:
            old_path = os.path.join(directory, filename)
            new_filename = filename.replace(old_pattern, new_pattern)
            new_path = os.path.join(directory, new_filename)

            try:
                os.rename(old_path, new_path)
                print(f"å·²é‡å‘½å: {filename} -> {new_filename}")
                renamed_count += 1
            except OSError as e:
                print(f"é‡å‘½åå¤±è´¥ {filename}: {e}")

    return f"å…±é‡å‘½åäº† {renamed_count} ä¸ªæ–‡ä»¶"

# ç»ƒä¹ 3: ç›®å½•æ ‘ç»“æ„æŸ¥çœ‹å™¨
def print_directory_tree(directory, indent=0):
    """æ‰“å°ç›®å½•æ ‘ç»“æ„"""
    if not os.path.exists(directory):
        print(f"ç›®å½•ä¸å­˜åœ¨: {directory}")
        return

    prefix = "  " * indent
    print(f"{prefix}ğŸ“ {os.path.basename(directory)}/")

    try:
        items = sorted(os.listdir(directory))
        for item in items:
            item_path = os.path.join(directory, item)
            if os.path.isdir(item_path):
                print_directory_tree(item_path, indent + 1)
            else:
                print(f"{prefix}  ğŸ“„ {item}")
    except PermissionError:
        print(f"{prefix}  ğŸ”’ æƒé™ä¸è¶³")

# æµ‹è¯•ç›®å½•æ ‘æŸ¥çœ‹å™¨
print("\né¡¹ç›®ç›®å½•ç»“æ„:")
print_directory_tree('python_learning')

# ç»ƒä¹ 4: ç®€å•çš„æ–‡ä»¶å‹ç¼©/è§£å‹
def create_zip_archive(source_dir, zip_name):
    """åˆ›å»ºZIPå‹ç¼©æ–‡ä»¶"""
    try:
        shutil.make_archive(zip_name, 'zip', source_dir)
        zip_path = zip_name + '.zip'
        if os.path.exists(zip_path):
            size = os.path.getsize(zip_path)
            print(f"ZIPæ–‡ä»¶å·²åˆ›å»º: {zip_path} ({size} bytes)")
            return True
    except Exception as e:
        print(f"åˆ›å»ºZIPå¤±è´¥: {e}")
    return False

# æµ‹è¯•ZIPåˆ›å»º
if create_zip_archive('python_learning/utils', 'utils_backup'):
    print("å¤‡ä»½åˆ›å»ºæˆåŠŸ")

# ===== æ¸…ç†ä¸´æ—¶æ–‡ä»¶ =====

print("\næ¸…ç†ç¤ºä¾‹æ–‡ä»¶...")
cleanup_files = [
    new_name,  # é‡å‘½åçš„æ–‡ä»¶
    csv_filename,
    json_filename,
    'python_learning/utils/utils_backup.zip'
]

for file_path in cleanup_files:
    try:
        if os.path.exists(file_path):
            if os.path.isdir(file_path):
                shutil.rmtree(file_path)
            else:
                os.remove(file_path)
            print(f"å·²æ¸…ç†: {file_path}")
    except OSError as e:
        print(f"æ¸…ç†å¤±è´¥ {file_path}: {e}")

print("æ–‡ä»¶æ“ä½œå­¦ä¹ å®Œæˆï¼æ–‡ä»¶æ“ä½œæ˜¯Pythonç¼–ç¨‹çš„åŸºç¡€ï¼ŒæŒæ¡è¿™äº›æŠ€å·§èƒ½è®©ä½ é«˜æ•ˆå¤„ç†å„ç§æ•°æ®å­˜å‚¨éœ€æ±‚ã€‚")
